{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab8042558b9a4bad8c021d1c3f426779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c96c74603cd4b509a66bee88758045f",
              "IPY_MODEL_df4763ff7f464a93ab4cca1834941f47",
              "IPY_MODEL_8fe39d99699a4c34bb50413191b94e2d"
            ],
            "layout": "IPY_MODEL_9c6b86ecac0744df97a58e1cec4efbf5"
          }
        },
        "7c96c74603cd4b509a66bee88758045f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_200b6e62c4c94d4e98b2e36367e30724",
            "placeholder": "​",
            "style": "IPY_MODEL_b94c2106e7fc4c7a8331cdc85e88ec9a",
            "value": "Airavata.gguf: 100%"
          }
        },
        "df4763ff7f464a93ab4cca1834941f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed3ce1f79754d629c74d6e3b4ff352d",
            "max": 13741862112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29f8f51e1b9d421a8c0db47c720b4594",
            "value": 13741862112
          }
        },
        "8fe39d99699a4c34bb50413191b94e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9cfdf4bee494218826f5d8ffa1a48ce",
            "placeholder": "​",
            "style": "IPY_MODEL_c81979bcd184449189f785ef962ab8b8",
            "value": " 13.7G/13.7G [03:34&lt;00:00, 55.3MB/s]"
          }
        },
        "9c6b86ecac0744df97a58e1cec4efbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200b6e62c4c94d4e98b2e36367e30724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b94c2106e7fc4c7a8331cdc85e88ec9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ed3ce1f79754d629c74d6e3b4ff352d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f8f51e1b9d421a8c0db47c720b4594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9cfdf4bee494218826f5d8ffa1a48ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81979bcd184449189f785ef962ab8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Demo"
      ],
      "metadata": {
        "id": "oGY_MpR-pZed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install llama-cpp\n",
        "\n",
        "!set LLAMA_CUBLAS=1\n",
        "!set CMAKE_ARGS=-DLLAMA_CUBLAS=on\n",
        "!set FORCE_CMAKE=1\n",
        "\n",
        "!python -m pip install llama-cpp-python==0.2.7 --prefer-binary --extra-index-url=https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/AVX2/cu122"
      ],
      "metadata": {
        "id": "9yQpqRI06M7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ac74a6-a5ba-4150-e48a-c4cdadfaf9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://jllllll.github.io/llama-cpp-python-cuBLAS-wheels/AVX2/cu122\n",
            "Collecting llama-cpp-python==0.2.7\n",
            "  Downloading https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/wheels/llama_cpp_python-0.2.7%2Bcu122-cp310-cp310-manylinux_2_31_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.7) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.7) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.7)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.7+cu122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Airavata.gguf\n",
        "\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "def read_token(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            return file.readline().strip()\n",
        "    except FileNotFoundError:\n",
        "        raise ValueError(f\"Token file not found: {file_path}\")\n",
        "\n",
        "# Define the model name and file\n",
        "model_name = \"ai4bharat/Airavata\"\n",
        "model_file = \"Airavata.gguf\"\n",
        "\n",
        "# Download the model from Hugging Face Hub\n",
        "model_path = hf_hub_download(\n",
        "    model_name,\n",
        "    filename=model_file,\n",
        "    local_dir='models/',  # Download the model to the \"models\" folder\n",
        ")\n",
        "\n",
        "print(\"Model path:\", model_path) # models/Airavata"
      ],
      "metadata": {
        "id": "YjOQoCms6VUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196,
          "referenced_widgets": [
            "ab8042558b9a4bad8c021d1c3f426779",
            "7c96c74603cd4b509a66bee88758045f",
            "df4763ff7f464a93ab4cca1834941f47",
            "8fe39d99699a4c34bb50413191b94e2d",
            "9c6b86ecac0744df97a58e1cec4efbf5",
            "200b6e62c4c94d4e98b2e36367e30724",
            "b94c2106e7fc4c7a8331cdc85e88ec9a",
            "9ed3ce1f79754d629c74d6e3b4ff352d",
            "29f8f51e1b9d421a8c0db47c720b4594",
            "f9cfdf4bee494218826f5d8ffa1a48ce",
            "c81979bcd184449189f785ef962ab8b8"
          ]
        },
        "outputId": "15b45f23-c35c-4072-b6d7-944903c94ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Airavata.gguf:   0%|          | 0.00/13.7G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab8042558b9a4bad8c021d1c3f426779"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model path: models/Airavata.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "MESSAGES = []\n",
        "\n",
        "def create_prompt_with_chat_format(messages, bos=\"<s>\", eos=\"</s>\", add_bos=True):\n",
        "    formatted_text = \"\"\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            formatted_text += \"<|system|>\\n\" + message[\"content\"] + \"\\n\"\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            formatted_text += \"<|user|>\\n\" + message[\"content\"] + \"\\n\"\n",
        "        elif message[\"role\"] == \"assistant\":\n",
        "            formatted_text += \"<|assistant|>\\n\" + message[\"content\"].strip() + eos + \"\\n\"\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Tulu chat template only supports 'system', 'user' and 'assistant' roles. Invalid role: {}.\".format(\n",
        "                    message[\"role\"]\n",
        "                )\n",
        "            )\n",
        "    formatted_text += \"<|assistant|>\\n\"\n",
        "    formatted_text = bos + formatted_text if add_bos else formatted_text\n",
        "    return formatted_text\n",
        "\n",
        "\n",
        "def select_llm() -> Llama:\n",
        "    return Llama(model_path=\"models/Airavata.gguf\", n_gpu_layers=-1, n_threads=2, n_ctx=4096, verbose=True)\n",
        "\n",
        "def get_answer(llm, messages, memory=5) -> str:\n",
        "    generation_kwargs = {\n",
        "      \"max_tokens\":200,\n",
        "      \"stop\":[\"</s>\"],\n",
        "      \"echo\":False,\n",
        "      \"top_k\":50,\n",
        "      \"top_p\":0.5\n",
        "    }\n",
        "    res = llm(create_prompt_with_chat_format(messages[-5:], add_bos=False), **generation_kwargs)\n",
        "\n",
        "    return res[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "FQg4SB9o6pJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = select_llm()"
      ],
      "metadata": {
        "id": "b-UG9ae56xT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445f6a74-81eb-4e6a-ec84-03999f61b342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "!wget https://raw.githubusercontent.com/AI4Bharat/IndicInstruct/main/demo/airavata_html.py\n",
        "from airavata_html import chat_html, js_code, update_html\n",
        "\n",
        "MESSAGES = []\n",
        "\n",
        "# Display the HTML and JavaScript\n",
        "display(HTML(chat_html + js_code))\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Define the Python function to process the input\n",
        "def process_input(user_input):\n",
        "    global MESSAGES, update_html\n",
        "    print(\"User:\",user_input, \"\\n\")\n",
        "    MESSAGES.append({\"role\": \"user\", \"content\": user_input})\n",
        "    response = get_answer(llm, MESSAGES)\n",
        "    MESSAGES.append({\"role\": \"assistant\", \"content\": response})\n",
        "    print(\"Airavata:\",response,\"\\n\")\n",
        "\n",
        "    user_input_escaped = user_input.replace(\"'\", \"\\\\'\").replace('\"', '\\\\\"')\n",
        "    response_escaped =  response = response.replace('\\n', '<br>').replace(\"'\", \"\\\\'\").replace('\"', '\\\\\"')\n",
        "\n",
        "\n",
        "    display(HTML(update_html.format(user_input=user_input_escaped, response=response_escaped)))\n",
        "\n",
        "# Register the Python function with the notebook\n",
        "from google.colab import output\n",
        "output.register_callback('process_input', process_input)\n",
        "print(\"[Debug]\\n\")"
      ],
      "metadata": {
        "id": "H-Wtiejo60Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Airavata from 🤗 Hugging Face Transformers"
      ],
      "metadata": {
        "id": "fl_sFYwx88Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"ai4bharat/Airavata\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXQUeo5m-iIg",
        "outputId": "f826d4f0-3f14-4c37-b638-8ad9dd4a3001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-06 04:43:05,043] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, weight, bias=None):\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IndicInstruct SFT Dataset"
      ],
      "metadata": {
        "id": "c6HvI-sHqiOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🤗 https://huggingface.co/datasets/ai4bharat/indic-instruct-data-v0.1"
      ],
      "metadata": {
        "id": "fzUJe-xrqmsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluations and Benchmarks"
      ],
      "metadata": {
        "id": "uhGEN-FTrRbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AI4Bharat/IndicInstruct/"
      ],
      "metadata": {
        "id": "N57gRAh2rTmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cb81d4-9289-4eb4-cd08-a25fc86af03e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IndicInstruct'...\n",
            "remote: Enumerating objects: 1122, done.\u001b[K\n",
            "remote: Counting objects: 100% (495/495), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 1122 (delta 424), reused 411 (delta 399), pack-reused 627\u001b[K\n",
            "Receiving objects: 100% (1122/1122), 30.69 MiB | 37.37 MiB/s, done.\n",
            "Resolving deltas: 100% (691/691), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd IndicInstruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spBlrf_m2aZ7",
        "outputId": "30ddebb8-a19e-4b03-e29c-83c1a05c4001"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IndicInstruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "lKp2gjMs3PH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following script evaluates the model given in arg1 with the entire evaluation suite and stores the results in the directory given in arg2\n",
        "!bash full_eval.sh ai4bharat/Airavata results"
      ],
      "metadata": {
        "id": "8fMyPNqfrXn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scripts to perform individual evaluations can be found in scripts/<eval>/<name_of_the_task.sh>\n",
        "\n",
        "# Eg. For hellaswag translated to indic languages:\n",
        "!bash scripts/indic_eval/hellaswag.sh\n",
        "\n",
        "# Eg. For ARC in English:\n",
        "!bash scripts/english_eval/arc.sh\n",
        "\n",
        "# Eg. For XLSum translate-test in English:\n",
        "!bash scripts/translate_test_eval/xlsum.sh\n",
        "\n",
        "# Feel free to modify the bash scripts as per your requirements for language, model name, few-shot examples etc."
      ],
      "metadata": {
        "id": "ujq3GSlI7W4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on IndicSentiment (Hindi) on a 5-shot setting\n",
        "!python3 -m eval.indicsentiment.run_eval \\\n",
        "    --ntrain 5 \\\n",
        "    --save_dir \"results/indicsentiment/airavata-5shot\" \\\n",
        "    --model_name_or_path \"ai4bharat/Airavata\" \\\n",
        "    --tokenizer_name_or_path \"ai4bharat/Airavata\" \\\n",
        "    --eval_batch_size 4"
      ],
      "metadata": {
        "id": "PhIxEiq_DxE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune Model"
      ],
      "metadata": {
        "id": "a0Rf_kZSpxGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AI4Bharat/IndicInstruct/"
      ],
      "metadata": {
        "id": "NYNibNi5F-g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "_KhjvF8SF_Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/finetune_lora_with_accelerate.sh"
      ],
      "metadata": {
        "id": "ThtyX0W3GBG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}